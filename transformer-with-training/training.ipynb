{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "257e14ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np  # reserved for later use\n",
    "import einops\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "5a57cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8830dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.vocab_size = 50257\n",
    "        self.embedding_dim = 1024\n",
    "        self.mlp_dim = 4 * self.embedding_dim\n",
    "        self.num_blocks = 4\n",
    "        self.num_heads = 8\n",
    "        self.context_len = 1024\n",
    "        self.attention_dim = self.embedding_dim // self.num_heads\n",
    "        # mps (Apple Silicon) support, reserved for further training\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "        # hyperparams\n",
    "        self.num_epochs = 2\n",
    "        self.lr = 3e-5\n",
    "        self.betas = (0.9, 0.95) # for controlling momentum\n",
    "        self.eps = 1e-8\n",
    "        self.weight_decay = 0.1\n",
    "\n",
    "        self.learnable_params_dict = {\"embedding\": self.vocab_size * self.embedding_dim, \"positional_embedding\": self.context_len * self.embedding_dim, \"MLPs (Weights)\": self.num_blocks * 2 * self.embedding_dim * self.mlp_dim, \"MLPs (Biases)\": self.num_blocks * (self.mlp_dim + self.embedding_dim), \"W_Qs\": self.num_blocks * self.embedding_dim * self.embedding_dim, \"W_Ks\": self.num_blocks * self.embedding_dim * self.embedding_dim, \"W_Vs\": self.num_blocks * self.embedding_dim * self.embedding_dim, \"W_Out\": self.num_blocks * self.embedding_dim * self.embedding_dim}\n",
    "        self.learnable_params = (lambda d: sum(d.values()))(self.learnable_params_dict)\n",
    "\n",
    "        self.non_learnable_params_dict = {\"deembedding (tied to embedding weights)\": self.vocab_size * self.embedding_dim}\n",
    "        self.non_learnable_params = (lambda d: sum(d.values()))(self.non_learnable_params_dict)\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "a7f93a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, B, T):\n",
    "        self.batch_size = B # num of sequences processed together in each batch\n",
    "        self.seq_len = T # how many tokens are in each sequence/batch\n",
    "    \n",
    "        with open(\"tiny_shakespeare.txt\", \"r\") as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        encoding = tokenizer.encode(text)\n",
    "        self.tokens = torch.tensor(encoding)\n",
    "\n",
    "        self.current_pos = 0 # maintain the index of the current data sample\n",
    "\n",
    "        print(f\"loaded {len(self.tokens)} tokens with batch size of {self.batch_size} sequences and {self.seq_len} tokens per sequence in the batch\")\n",
    "        print(f\"each epoch has {len(self.tokens) / (self.batch_size * self.seq_len)} batches, with {self.seq_len * self.batch_size} tokens per batch, for a total of {self.seq_len * self.batch_size * (len(self.tokens) / (self.batch_size * self.seq_len))} tokens\")\n",
    "        print(\"*\"*50)\n",
    "        \n",
    "    def next_batch(self):\n",
    "        B, T = self.batch_size, self.seq_len\n",
    "        x = self.tokens[self.current_pos:self.current_pos+B*T]\n",
    "        y = self.tokens[self.current_pos+1:self.current_pos+B*T+1]\n",
    "        x = x.view(B, T)\n",
    "        y = y.view(B, T)\n",
    "        self.current_pos += B * T\n",
    "\n",
    "        if (len(self.tokens) - self.current_pos + 1) < B * T:\n",
    "            self.current_pos = 0\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "6078d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.W_E = nn.Embedding(config.vocab_size, config.embedding_dim)\n",
    "        self.W_pos = nn.Embedding(config.context_len, config.embedding_dim)\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        # Don't convert to tensor if already a tensor\n",
    "        if not isinstance(tokens, torch.Tensor):\n",
    "            tokens = torch.tensor(tokens)\n",
    "        \n",
    "        embeddings = self.W_E(tokens)\n",
    "\n",
    "        # Create positions tensor on the same device as tokens\n",
    "        positions = torch.arange(tokens.shape[1], device=tokens.device)\n",
    "        position_embeddings = self.W_pos(positions)\n",
    "\n",
    "        return embeddings + position_embeddings\n",
    "\n",
    "class DeEmbedding(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.W_D = nn.Linear(config.embedding_dim, config.vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.W_D(x)\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "42f447d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.W_Q = nn.Linear(config.embedding_dim, config.embedding_dim, bias=False)\n",
    "        self.W_K = nn.Linear(config.embedding_dim, config.embedding_dim, bias=False)\n",
    "        self.W_V = nn.Linear(config.embedding_dim, config.embedding_dim, bias=False)\n",
    "        \n",
    "        self.W_out = nn.Linear(config.embedding_dim, config.embedding_dim, bias=False)\n",
    "\n",
    "        self.num_heads = config.num_heads\n",
    "        self.attention_dim = config.attention_dim\n",
    "        \n",
    "        # Register causal mask as buffer\n",
    "        self.register_buffer(\"causal_mask\", torch.tril(torch.ones(config.context_len, config.context_len)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        \n",
    "        Q = einops.rearrange(self.W_Q(x), 'batch seq (head dim) -> batch head seq dim', head=self.num_heads)\n",
    "        K = einops.rearrange(self.W_K(x), 'batch seq (head dim) -> batch head seq dim', head=self.num_heads)\n",
    "        V = einops.rearrange(self.W_V(x), 'batch seq (head dim) -> batch head seq dim', head=self.num_heads)\n",
    "\n",
    "        # Calculate attention scores\n",
    "        scores = (Q @ K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.attention_dim))\n",
    "        \n",
    "        # Apply causal mask\n",
    "        scores = scores.masked_fill(self.causal_mask[:T, :T] == 0, float('-inf'))\n",
    "        \n",
    "        # Apply softmax\n",
    "        QK = torch.softmax(scores, dim=-1)\n",
    "\n",
    "        QKV = einops.rearrange(QK @ V, 'batch head seq dim -> batch seq (head dim)', head=self.num_heads)\n",
    "        QKV_Out = self.W_out(QKV)\n",
    "\n",
    "        return QKV_Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "2142239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(config.embedding_dim, config.mlp_dim)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.layer2 = nn.Linear(config.mlp_dim, config.embedding_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer2(self.gelu(self.layer1(x)))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "154e6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.Attention_Layers = Attention(config)\n",
    "        self.MLP_Layers = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.Attention_Layers(x)\n",
    "        return x + self.MLP_Layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "d97092ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = Embedding(config)\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(config) for i in range(config.num_blocks)\n",
    "        ])\n",
    "\n",
    "        self.deembed = DeEmbedding(config)\n",
    "        self.deembed.W_D.weight = self.embed.W_E.weight  # tie weights\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.embed(x)\n",
    "        # print(f\"after embed: {x}\")\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        x = self.deembed(x)\n",
    "        # print(f\"after deembed: {x}\")\n",
    "        x = torch.softmax(x, dim=-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "2db70dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learnable params dict: {'embedding': 51463168, 'positional_embedding': 1048576, 'MLPs (Weights)': 33554432, 'MLPs (Biases)': 20480, 'W_Qs': 4194304, 'W_Ks': 4194304, 'W_Vs': 4194304, 'W_Out': 4194304}\n",
      "total # of learnable params: 102,863,872\n",
      "non-learnable params dict: {'deembedding (tied to embedding weights)': 51463168}\n",
      "total # of non-learnable params: 51,463,168\n",
      "** total # of params: 154,327,040 **\n",
      "theoretical start loss: 10.82490511970208\n",
      "Using device: mps\n",
      "loaded 338025 tokens with batch size of 8 sequences and 1024 tokens per sequence in the batch\n",
      "each epoch has 41.2628173828125 batches, with 8192 tokens per batch, for a total of 338025.0 tokens\n",
      "**************************************************\n",
      "Epoch 1/2\n",
      "Batch 0/41, Loss: 10.8006\n",
      "Batch 1/41, Loss: 10.8043\n",
      "Batch 2/41, Loss: 10.7966\n",
      "Batch 3/41, Loss: 10.7992\n",
      "Batch 4/41, Loss: 10.8020\n",
      "Batch 5/41, Loss: 10.8076\n",
      "Batch 6/41, Loss: 10.8030\n",
      "Batch 7/41, Loss: 10.8025\n",
      "Batch 8/41, Loss: 10.7965\n",
      "Batch 9/41, Loss: 10.8046\n",
      "Batch 10/41, Loss: 10.8028\n",
      "Batch 11/41, Loss: 10.8074\n",
      "Batch 12/41, Loss: 10.8113\n",
      "Batch 13/41, Loss: 10.8091\n",
      "Batch 14/41, Loss: 10.8107\n",
      "Batch 15/41, Loss: 10.8066\n",
      "Batch 16/41, Loss: 10.8008\n",
      "Batch 17/41, Loss: 10.8052\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[556]\u001b[39m\u001b[32m, line 91\u001b[39m\n\u001b[32m     89\u001b[39m display_params_info()\n\u001b[32m     90\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtheoretical start loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.log(config.vocab_size)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m model = \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m inference(config, model)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[556]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mtraining\u001b[39m\u001b[34m(model_config)\u001b[39m\n\u001b[32m     72\u001b[39m optimizer.zero_grad()\n\u001b[32m     73\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch % \u001b[32m1\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     77\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_batches\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PAIR/t9r-class/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PAIR/t9r-class/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PAIR/t9r-class/.venv/lib/python3.12/site-packages/torch/optim/adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PAIR/t9r-class/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PAIR/t9r-class/.venv/lib/python3.12/site-packages/torch/optim/adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PAIR/t9r-class/.venv/lib/python3.12/site-packages/torch/optim/adam.py:405\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight_decay != \u001b[32m0\u001b[39m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m decoupled_weight_decay:\n\u001b[32m    404\u001b[39m         \u001b[38;5;66;03m# Perform stepweight decay\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m         \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    407\u001b[39m         \u001b[38;5;66;03m# Nested if is necessary to bypass jitscript rules\u001b[39;00m\n\u001b[32m    408\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m differentiable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(weight_decay, Tensor):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def inference(inference_config, inference_model):\n",
    "    text = \"They fear us\"\n",
    "    tokens = tokenizer.encode(text)\n",
    "    x = torch.tensor(tokens)\n",
    "    x = x.unsqueeze(0)\n",
    "    \n",
    "    # Move input tensor to the same device as the model\n",
    "    if inference_model:\n",
    "        print(\"using passed in model for inference\")\n",
    "        device = next(inference_model.parameters()).device\n",
    "        x = x.to(device)\n",
    "    else:\n",
    "        inference_model = Transformer(inference_config)\n",
    "        print(\"using random model for inference\")\n",
    "        device = inference_config.device\n",
    "        x = x.to(device)\n",
    "\n",
    "    out = inference_model(x)\n",
    "    pred_tokens = out.argmax(dim=-1)\n",
    "    print(f\"predicted tokens: {pred_tokens}\")\n",
    "\n",
    "    # Only take the prediction from the last position (next token after \"fox\")\n",
    "    next_token = pred_tokens[0, -1].item()\n",
    "    predicted_word = tokenizer.decode([next_token])\n",
    "    print(f\"predicted word: {predicted_word}\")\n",
    "\n",
    "    print(f\"full sentence: {text}{predicted_word}\")\n",
    "\n",
    "    print(\"*\"*50)\n",
    "    print(\"sanity check: all predicted tokens\")\n",
    "    for num, token in enumerate(pred_tokens.flatten()):\n",
    "        decoded = tokenizer.decode([token.item()])\n",
    "        \n",
    "        if num == (len(pred_tokens.flatten()) - 1):\n",
    "            print(f\"** Token {token} -> '{decoded}' **\")\n",
    "        else:\n",
    "            print(f\"Token {token} -> '{decoded}'\")\n",
    "\n",
    "def training(model_config):\n",
    "    device = model_config.device\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.manual_seed(42)\n",
    "\n",
    "    train_loader = DataLoader(8, 1024)\n",
    "\n",
    "    model = Transformer(model_config).to(device)\n",
    "    # model = torch.compile(model) # temporary comment to resolve errors with metal\n",
    "    losses = []\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9, 0.95), eps=1e-8, weight_decay = 0.1)\n",
    "\n",
    "    for epoch in range(model_config.num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{model_config.num_epochs}\")\n",
    "\n",
    "        # Reset data loader position at the start of each epoch\n",
    "        train_loader.current_pos = 0\n",
    "\n",
    "        num_batches = int(len(train_loader.tokens) / (train_loader.batch_size * train_loader.seq_len))\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            x, y = train_loader.next_batch()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 1 == 0:\n",
    "                print(f\"Batch {batch}/{num_batches}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def display_params_info():\n",
    "    print(f\"learnable params dict: {config.learnable_params_dict}\")\n",
    "    print(f\"total # of learnable params: {config.learnable_params:,}\")\n",
    "    print(f\"non-learnable params dict: {config.non_learnable_params_dict}\")\n",
    "    print(f\"total # of non-learnable params: {config.non_learnable_params:,}\")\n",
    "    print(f\"** total # of params: {(config.learnable_params + config.non_learnable_params):,} **\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    display_params_info()\n",
    "    print(f\"theoretical start loss: {np.log(config.vocab_size)}\")\n",
    "    model = training(config)\n",
    "    inference(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dfc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## TODOs\n",
    "# - [x] working training\n",
    "# - [ ] Add support for displaying calculated # of learnable and non-learnable params\n",
    "# - [ ] Attention sink?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
